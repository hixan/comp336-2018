{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "In this assignment you will implement a non-trivial problem that processes Big Data. To facilitate its processing in a regular computer, the actual amount of data will not be big, but the techniques that you will implement would scale to larger volumes of data.\n",
    "\n",
    "This assignment is worth 15% of the total assessment of the unit.\n",
    "\n",
    "This assignment relates to the following Learning Outcomes:\n",
    "* Apply Map-reduce techniques to a number of problems that involve Big Data.\n",
    "* Apply Big Data techniques to data mining.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission deadline: Friday Week 12, 11:55pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code unzips the data stored in tweets.zip. This is the same data you used in Assignment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "if not Path('10000 tweets-NEW.json').exists():\n",
    "    print(\"Unzipping tweets\")\n",
    "    with zipfile.ZipFile('cleaned-tweets.zip') as myzip:\n",
    "        myzip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements a [Python generator](https://wiki.python.org/moin/Generators) that simulates a stream of tweets. You will use this iterator in some of the following tasks. The function uses the `yield` statement instead of a `return` statement so that it does not need to read the entire file into memory. By doing this, the function can work with files of  unlimited size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def stream_tweets():\n",
    "    with open('10000 tweets-NEW.json', encoding='iso8859-1') as jfile:\n",
    "        for line in jfile:\n",
    "            try:\n",
    "                next_tweet = json.loads(line)\n",
    "            except:\n",
    "                continue # yield next tweet instead of returning str\n",
    "            yield next_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be a demonstration of the use of this code in the lectures and workshops. Below is an example of how it can be used in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'tag:search.twitter.com,2005:715690137900941312', 'objectType': 'activity', 'actor': {'objectType': 'person', 'id': 'id:twitter.com:18064228', 'link': 'http://www.twitter.com/Intelledox', 'displayName': 'Intelledox', 'postedTime': '2008-12-11T23:47:55.000Z', 'image': 'https://pbs.twimg.com/profile_images/485981380585603072/inMuMtJ7_normal.png', 'summary': \"Intelledox's mobile-ready digitalization software helps over 1 million people to do business faster, smarter & efficiently Digitalize your business process now!\", 'links': [{'href': 'http://www.intelledox.com', 'rel': 'me'}], 'friendsCount': 486, 'followersCount': 549, 'listedCount': 24, 'statusesCount': 1188, 'twitterTimeZone': 'Canberra', 'verified': False, 'utcOffset': '39600', 'preferredUsername': 'Intelledox', 'languages': ['en'], 'location': {'objectType': 'place', 'displayName': 'Canberra, Australia'}, 'favoritesCount': 55}, 'verb': 'post', 'postedTime': '2016-04-01T00:00:00.000Z', 'generator': {'displayName': 'HubSpot', 'link': 'http://www.hubspot.com/'}, 'provider': {'objectType': 'service', 'displayName': 'Twitter', 'link': 'http://www.twitter.com'}, 'link': 'http://twitter.com/Intelledox/statuses/715690137900941312', 'body': 'Register for #Convergence2016 to hear@ChelleMelbourne talk about how to manage change through digital transformation https://t.co/7pxwwDeaXm', 'object': {'objectType': 'note', 'id': 'object:search.twitter.com,2005:715690137900941312', 'summary': 'Register for #Convergence2016 to hear@ChelleMelbourne talk about how to manage change through digital transformation https://t.co/7pxwwDeaXm', 'link': 'http://twitter.com/Intelledox/statuses/715690137900941312', 'postedTime': '2016-04-01T00:00:00.000Z'}, 'favoritesCount': 0, 'twitter_entities': {'hashtags': [{'text': 'Convergence2016', 'indices': [13, 29]}], 'urls': [{'url': 'https://t.co/7pxwwDeaXm', 'expanded_url': 'http://hubs.ly/H02w_rn0', 'display_url': 'hubs.ly/H02w_rn0', 'indices': [117, 140]}], 'user_mentions': [], 'symbols': []}, 'twitter_filter_level': 'low', 'twitter_lang': 'en', 'retweetCount': 0, 'gnip': {'matching_rules': [{'value': 'bio_location: \"Australia\"', 'tag': None}, {'value': 'bio_location: \"Canberra\"', 'tag': None}], 'urls': [{'url': 'https://t.co/7pxwwDeaXm', 'expanded_url': 'http://www.cvent.com/events/convergence-2016-optimising-your-organisational-change/agenda-77418453122540c5aa767dd59702ef91.aspx', 'expanded_status': 200}], 'klout_score': 40, 'language': {'value': 'en'}, 'profileLocations': [{'objectType': 'place', 'geo': {'type': 'point', 'coordinates': [149.12807, -35.28346]}, 'address': {'country': 'Australia', 'countryCode': 'AU', 'locality': 'Canberra', 'region': 'Australian Capital Territory'}, 'displayName': 'Canberra, Australian Capital Territory, Australia'}]}}\n",
      "{'id': 'tag:search.twitter.com,2005:715690143449899009', 'objectType': 'activity', 'actor': {'objectType': 'person', 'id': 'id:twitter.com:188921458', 'link': 'http://www.twitter.com/losebabyweight1', 'displayName': 'losebabyweight', 'postedTime': '2010-09-09T22:40:10.000Z', 'image': 'https://pbs.twimg.com/profile_images/522696965503455233/WfF2aJ7N_normal.png', 'summary': 'http://www.losebabyweight.com.au offers mums safe and proven plans to lose weight. Lose an average of 1kg a week.', 'links': [{'href': 'http://www.losebabyweight.com.au', 'rel': 'me'}], 'friendsCount': 218, 'followersCount': 1960, 'listedCount': 17, 'statusesCount': 14439, 'twitterTimeZone': 'Sydney', 'verified': False, 'utcOffset': '39600', 'preferredUsername': 'losebabyweight1', 'languages': ['en'], 'location': {'objectType': 'place', 'displayName': 'Australia'}, 'favoritesCount': 0}, 'verb': 'post', 'postedTime': '2016-04-01T00:00:01.000Z', 'generator': {'displayName': 'Facebook', 'link': 'http://www.facebook.com/twitter'}, 'provider': {'objectType': 'service', 'displayName': 'Twitter', 'link': 'http://www.twitter.com'}, 'link': 'http://twitter.com/losebabyweight1/statuses/715690143449899009', 'body': 'CONGRATULATIONS Suzie Walker on both your beautiful little man and your FANTASTIC commitment and hard work. You... https://t.co/m4QLVq0BTr', 'object': {'objectType': 'note', 'id': 'object:search.twitter.com,2005:715690143449899009', 'summary': 'CONGRATULATIONS Suzie Walker on both your beautiful little man and your FANTASTIC commitment and hard work. You... https://t.co/m4QLVq0BTr', 'link': 'http://twitter.com/losebabyweight1/statuses/715690143449899009', 'postedTime': '2016-04-01T00:00:01.000Z'}, 'favoritesCount': 0, 'twitter_entities': {'hashtags': [], 'urls': [{'url': 'https://t.co/m4QLVq0BTr', 'expanded_url': 'http://fb.me/WUTD9TnQ', 'display_url': 'fb.me/WUTD9TnQ', 'indices': [115, 138]}], 'user_mentions': [], 'symbols': []}, 'twitter_filter_level': 'low', 'twitter_lang': 'en', 'retweetCount': 0, 'gnip': {'matching_rules': [{'value': 'bio_location: \"Australia\"', 'tag': None}], 'urls': [{'url': 'https://t.co/m4QLVq0BTr', 'expanded_url': 'https://www.facebook.com/photo.php?fbid=1257229527624685', 'expanded_status': 403}], 'klout_score': 44, 'language': {'value': 'en'}, 'profileLocations': [{'objectType': 'place', 'geo': {'type': 'point', 'coordinates': [135, -25]}, 'address': {'country': 'Australia', 'countryCode': 'AU'}, 'displayName': 'Australia'}]}}\n",
      "{'id': 'tag:search.twitter.com,2005:715690141306650624', 'objectType': 'activity', 'actor': {'objectType': 'person', 'id': 'id:twitter.com:97578801', 'link': 'http://www.twitter.com/wantirnaweather', 'displayName': 'Wantirna Weather', 'postedTime': '2009-12-18T02:34:57.000Z', 'image': 'https://pbs.twimg.com/profile_images/580069194/Eclipse_003vsm_normal.jpg', 'summary': 'Personal Weather Station from Wantirna, Victoria, Australia.', 'links': [{'href': 'http://www.vic-weather.info', 'rel': 'me'}], 'friendsCount': 28, 'followersCount': 80, 'listedCount': 12, 'statusesCount': 66248, 'twitterTimeZone': 'Melbourne', 'verified': False, 'utcOffset': '39600', 'preferredUsername': 'wantirnaweather', 'languages': ['en'], 'location': {'objectType': 'place', 'displayName': 'Victoria, Australia'}, 'favoritesCount': 1}, 'verb': 'post', 'postedTime': '2016-04-01T00:00:01.000Z', 'generator': {'displayName': 'Weather Display Tweet', 'link': 'http://www.weather-display.com'}, 'provider': {'objectType': 'service', 'displayName': 'Twitter', 'link': 'http://www.twitter.com'}, 'link': 'http://twitter.com/wantirnaweather/statuses/715690141306650624', 'body': 'Wantirna, VIC, AU 11:00 AM Temp 19.8Â°C, RH 67pct, Winds NNW @ 0.0 km/h, Rain Today  0 mm, 1014.3 hpa &amp; Steady. #vicweather', 'object': {'objectType': 'note', 'id': 'object:search.twitter.com,2005:715690141306650624', 'summary': 'Wantirna, VIC, AU 11:00 AM Temp 19.8Â°C, RH 67pct, Winds NNW @ 0.0 km/h, Rain Today  0 mm, 1014.3 hpa &amp; Steady. #vicweather', 'link': 'http://twitter.com/wantirnaweather/statuses/715690141306650624', 'postedTime': '2016-04-01T00:00:01.000Z'}, 'favoritesCount': 0, 'twitter_entities': {'hashtags': [{'text': 'vicweather', 'indices': [115, 126]}], 'urls': [], 'user_mentions': [], 'symbols': []}, 'twitter_filter_level': 'low', 'twitter_lang': 'en', 'retweetCount': 0, 'gnip': {'matching_rules': [{'value': 'bio_location: \"Australia\"', 'tag': None}], 'klout_score': 28, 'language': {'value': 'en'}, 'profileLocations': [{'objectType': 'place', 'geo': {'type': 'point', 'coordinates': [145, -37]}, 'address': {'country': 'Australia', 'countryCode': 'AU', 'region': 'Victoria'}, 'displayName': 'Victoria, Australia'}]}}\n",
      "{'id': 'tag:search.twitter.com,2005:715690146062950400', 'objectType': 'activity', 'actor': {'objectType': 'person', 'id': 'id:twitter.com:3266593548', 'link': 'http://www.twitter.com/OnAussie', 'displayName': \"What's On Aussie\", 'postedTime': '2015-07-03T02:09:37.000Z', 'image': 'https://pbs.twimg.com/profile_images/616796684706672640/vprn5HK4_normal.jpg', 'summary': 'Connecting local communities with their people, news, businesses and events.', 'links': [{'href': 'http://WhatsOnAussie.com.au', 'rel': 'me'}], 'friendsCount': 60, 'followersCount': 37, 'listedCount': 11, 'statusesCount': 946, 'twitterTimeZone': None, 'verified': False, 'utcOffset': None, 'preferredUsername': 'OnAussie', 'languages': ['en'], 'location': {'objectType': 'place', 'displayName': 'Australia'}, 'favoritesCount': 84}, 'verb': 'post', 'postedTime': '2016-04-01T00:00:02.000Z', 'generator': {'displayName': 'Facebook', 'link': 'http://www.facebook.com/twitter'}, 'provider': {'objectType': 'service', 'displayName': 'Twitter', 'link': 'http://www.twitter.com'}, 'link': 'http://twitter.com/OnAussie/statuses/715690146062950400', 'body': 'So much to see and do when you Visit Central Australia\\n\"We have our own kind of beaches in the #RedCentreNT! The... https://t.co/eRyP7eTk9X', 'object': {'objectType': 'note', 'id': 'object:search.twitter.com,2005:715690146062950400', 'summary': 'So much to see and do when you Visit Central Australia\\n\"We have our own kind of beaches in the #RedCentreNT! The... https://t.co/eRyP7eTk9X', 'link': 'http://twitter.com/OnAussie/statuses/715690146062950400', 'postedTime': '2016-04-01T00:00:02.000Z'}, 'favoritesCount': 0, 'twitter_entities': {'hashtags': [{'text': 'RedCentreNT', 'indices': [95, 107]}], 'urls': [{'url': 'https://t.co/eRyP7eTk9X', 'expanded_url': 'http://fb.me/4tbRKQpgN', 'display_url': 'fb.me/4tbRKQpgN', 'indices': [116, 139]}], 'user_mentions': [], 'symbols': []}, 'twitter_filter_level': 'low', 'twitter_lang': 'en', 'retweetCount': 0, 'gnip': {'matching_rules': [{'value': 'bio_location: \"Australia\"', 'tag': None}], 'urls': [{'url': 'https://t.co/eRyP7eTk9X', 'expanded_url': 'https://www.facebook.com/photo.php?fbid=1022848134476636', 'expanded_status': 403}], 'klout_score': 32, 'language': {'value': 'en'}, 'profileLocations': [{'objectType': 'place', 'geo': {'type': 'point', 'coordinates': [135, -25]}, 'address': {'country': 'Australia', 'countryCode': 'AU'}, 'displayName': 'Australia'}]}}\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for s in stream_tweets():\n",
    "    if counter > 3:\n",
    "        break\n",
    "    counter += 1\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (5 marks)\n",
    "Fill the gaps in the class below that processes the stream and issues the following standing queries:\n",
    "\n",
    "* (1 mark) The length of the shortest tweet and the length of the longest tweet so far.\n",
    "* (2 marks) The twitter ID of the person who has posted most tweets in the last 1000 posts.\n",
    "* (2 marks) The twitter ID of the most active twitter when we apply an exponentially decaying window with $c=10^{-3}$ and a threshold of 0.5.\n",
    "\n",
    "In your implementation, make sure that the system scales well to unlimited streams, and answer the following question:\n",
    "\n",
    "1. How much memory do you need to reserve to keep the information about each of the standing queries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: this question needs fixing\n",
    "part 3, make the algorithm better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "class StreamProcessor:\n",
    "    \n",
    "    shortest = None\n",
    "    longest = None\n",
    "    frequency = []\n",
    "    active = Counter()\n",
    "    gi = 0\n",
    "    \n",
    "    def _step_rval(self):\n",
    "        return {'shortest': self.shortest,\n",
    "               'longest': self.longest,\n",
    "               'most_frequent': max(Counter(self.frequency)),\n",
    "               'most_active': max(self.active, key=lambda x: self.active[x])}\n",
    "    \n",
    "    # end of class variables\n",
    "    def step(self, item):\n",
    "        \"\"\"Process one item from the stream and return the answers to the\n",
    "        standing queries as a Python dictionary with the following keys:\n",
    "          - shortest\n",
    "          - longest\n",
    "          - most_frequent\n",
    "          - most_active\n",
    "        \"\"\"\n",
    "        userid = item['actor']['id']\n",
    "        post = item['body']\n",
    "        l = len(post)\n",
    "        self.frequency.append(userid)\n",
    "        self.frequency = self.frequency[-1000:] # cut off entries before last 1000.\n",
    "        \n",
    "        # apply decay to all users\n",
    "        # mathematical equivalent of decay in growth\n",
    "        # so dont have to iterate over whole counter, only increment the growth indicator\n",
    "        # (IE each time add a larger number, and occasionally when numbers get too big \n",
    "        # multiply down to managable size, and reset growth indicator)\n",
    "        # note: I can prove this mathematically\n",
    "        if self.gi > 1000:\n",
    "            for k in self.active:\n",
    "                self.active[k] = self.active[k]*(.999**self.gi)\n",
    "                self.gi = 0\n",
    "        # add this tweet to activity\n",
    "        self.active[userid] += 1/(.999**self.gi)\n",
    "        self.gi += 1\n",
    "        \n",
    "        # initialize lowest and highest\n",
    "        if self.shortest is None:\n",
    "            self.shortest = l\n",
    "            self.longest = l\n",
    "            return self._step_rval() # no more calculation\n",
    "        \n",
    "        if l<self.shortest:\n",
    "            self.shortest = l\n",
    "        if l > self.longest:\n",
    "            self.longest = l\n",
    "        \n",
    "        return self._step_rval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum value n can get to with growth indicator cutoff = n\n",
      "1717.9225742264064 632.3045752290355\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "s = 0\n",
    "s_ = 0\n",
    "for i in range(n):\n",
    "    s_ *= .999\n",
    "    s_ += 1\n",
    "    s += 1/(.999**i)\n",
    "print('maximum value n can get to with growth indicator cutoff = n')\n",
    "print(s, s_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will apply the stream processor to the first 5 elements of the stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shortest': 140, 'longest': 140, 'most_frequent': 'id:twitter.com:18064228', 'most_active': 'id:twitter.com:18064228'}\n",
      "{'shortest': 138, 'longest': 140, 'most_frequent': 'id:twitter.com:188921458', 'most_active': 'id:twitter.com:188921458'}\n",
      "{'shortest': 127, 'longest': 140, 'most_frequent': 'id:twitter.com:97578801', 'most_active': 'id:twitter.com:97578801'}\n",
      "{'shortest': 127, 'longest': 140, 'most_frequent': 'id:twitter.com:97578801', 'most_active': 'id:twitter.com:3266593548'}\n",
      "{'shortest': 127, 'longest': 140, 'most_frequent': 'id:twitter.com:97578801', 'most_active': 'id:twitter.com:225568917'}\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "stream = StreamProcessor()\n",
    "for s in stream_tweets():\n",
    "    if s == 'Tweet error':\n",
    "        continue\n",
    "    if counter >= 5:\n",
    "        break\n",
    "    counter += 1\n",
    "    print(stream.step(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (5 marks)\n",
    "Apply the minhashing techniques we have covered in week 7 to determine the set of near-duplicates among the tweet posts. For this exercise use only the first 500 tweet posts (so that you do not need to wait too long). To complete this assignment you can reuse code from the lecture notebooks and from the workshop exercises. Use your judgement to determine the parameters and answer the following questions:\n",
    "\n",
    "1. What value of $k$ did you use to represent the $k$-shingles and why?\n",
    "2. Did you hash the $k$-shingles and why?\n",
    "3. If you hashed the $k$-shingles, how many buckets did you use and why?\n",
    "4. How many hashes did you use for minhashing, how many buckets, and why?\n",
    "5. How many bands and rows did you use for locality-sensitive hashing and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations, count\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "# implementation:\n",
    "# k_shingles function creates a zip of k copies of the tweet, each\n",
    "# offset by one more then the previous and returns the columns. EG:\n",
    "#          >>> k_shingles('testing', 3)\n",
    "# internally:  v v v v v\n",
    "#comprehension t e s t i\n",
    "#   function   e s t i n\n",
    "#   returns    s t i n g\n",
    "# zip transposes\n",
    "# map applies the hashing function\n",
    "#          <<< {'tes','est','sti','tin','ing'} \n",
    "# \n",
    "# note: zip only returns values while arguments have elements at the\n",
    "# current index.\n",
    "# \n",
    "# this method of computing k_shingles is memory intensive, but has\n",
    "# a lower time complexity (and is very pythonic). The memory shouldnt\n",
    "# be an issue as tweets are all below 280 characters (so (280-k) * k)\n",
    "def k_shingles(tweet, k, h=lambda x:hash(''.join(x))):\n",
    "    if len(tweet) < k:\n",
    "        return tweet\n",
    "    else:\n",
    "        return set(map(h, zip(*[tweet[i:len(tweet)-(k-i-1)] for i in range(k)])))\n",
    "\n",
    "# print(k_shingles('0123456789', 3))\n",
    "# print(k_shingles('test', 3, h=hash))\n",
    "# print(k_shingles('tesa', 3, h=hash))\n",
    "\n",
    "# for easier debugging\n",
    "Tweet = namedtuple('Tweet', ['body','id'])\n",
    "\n",
    "tweetset = {t['actor']['id']:Tweet(t['body'], t['actor']['id']) for _, t in zip(range(500), stream_tweets())}\n",
    "#tweetset = {i: Tweet(a, i) for i, a in enumerate(['abc','abcd','zeqr', 'abacus', 'c', 'abcde'])}\n",
    "buckets = 2**64\n",
    "k = 20\n",
    "hash_count = 400\n",
    "# creates functions of the form hash_function(1) = lambda s:hash(s+str(1))%buckets\n",
    "#                             # hash_function(1)('test') = some integer between 0 and buckets.\n",
    "hash_function = lambda i: lambda s: hash(str(s)+str(i))%buckets\n",
    "# print(hash_function(3)('a'))\n",
    "hash_functions = [hash_function(i) for i in range(hash_count)]\n",
    "# define signature as a named tuple (instead of an anonymous tuple)\n",
    "# helps for knowing what objects are (as python is duck typed)\n",
    "Signature = namedtuple('Signature', ['id', 'hash_values'])\n",
    "\n",
    "def similarity(signature1, signature2):\n",
    "    similar = 0\n",
    "    for v1, v2 in zip(signature1.hash_values, signature2.hash_values):\n",
    "        if v1 == v2:\n",
    "            similar += 1\n",
    "    return similar / hash_count\n",
    "\n",
    "# basically a constructor for the Signature namedtuple\n",
    "def signature(tweet, k=k, hash_functions=hash_functions):\n",
    "    return Signature(tweet.id, tuple(min(map(h, k_shingles(tweet.body, k))) for h in hash_functions))\n",
    "        # does not return a generator of the signature as it may need to be accessed many times.\n",
    "\n",
    "# signatures = [signature(v) for k, v in tweetset.items()]\n",
    "\n",
    "def signature_sensitivity_hashing(signature, row_size=3, hash_function=hash_functions[0]):\n",
    "    bands = len(signature.hash_values)//row_size\n",
    "    new_hash_values = tuple([hash_function(signature.hash_values[i*row_size:(i+1)*row_size]) for i in range(bands)] +\n",
    "                                    [hash_function(signature.hash_values[:-len(signature.hash_values)%bands])])\n",
    "    # sometimes the second slice will return [:0] meaning the same hash is always returned\n",
    "    # (when hash_count%row_size==0)\n",
    "    # this is accounted for below:\n",
    "    return Signature(signature.id, new_hash_values\n",
    "                     [:-1 if len(signature.hash_values)%row_size==0 else len(new_hash_values)])\n",
    "\n",
    "# a = signature_sensitivity_hashing(signatures[0], row_size=10)\n",
    "# b = signatures[0]\n",
    "# print(len(a.hash_values), len(b.hash_values)/10)\n",
    "\n",
    "def similarity_sets(tweetset, k, hash_functions, row_count, similarity_cutoff, precalc_similarities=None):\n",
    "    # when similarity cutoff < 0; this will essentially s\n",
    "    hash_count = len(hash_functions)\n",
    "    signatures = [signature_sensitivity_hashing(signature_sensitivity_hashing(signature(tweet,\n",
    "                                                                                        k=k,\n",
    "                                                                                        hash_functions=hash_functions),\n",
    "                                                                              row_size=row_count,\n",
    "                                                                              hash_function=hash_functions[0]))\n",
    "                  for i, tweet in tweetset.items()]\n",
    "\n",
    "    # create lookup table of similarities (and dont repeat calculation if it was provided)\n",
    "    if precalc_similarities is None:\n",
    "        sims = {key1 : {key2 : None for key2 in tweetset} for key1 in tweetset}\n",
    "        for s1, s2 in combinations(signatures, 2):\n",
    "            sim = similarity(s1, s2)\n",
    "            sims[s1.id][s2.id] = sim\n",
    "            sims[s2.id][s1.id] = sim # it is a symmetric matrix\n",
    "    else:\n",
    "        sims = precalc_similarities\n",
    "        \n",
    "    if similarity_cutoff < 0:\n",
    "        return [set(tweetset.keys())], sims\n",
    "    sets = []\n",
    "    for tweet in tweetset:\n",
    "        added=False\n",
    "        for s in sets:\n",
    "            for t in s:\n",
    "                # min clustering\n",
    "                if sims[tweet][t] > similarity_cutoff:\n",
    "                    s.add(tweet)\n",
    "                    added=True # go on to the next tweet\n",
    "                    break\n",
    "            if added:\n",
    "                break\n",
    "        if not added:\n",
    "            sets.append(set([tweet]))\n",
    "    return sets, sims\n",
    "        \n",
    "    \n",
    "    \n",
    "# for t1, t2 in combinations([signature(v) for k, v in tweetset.items()], 2):\n",
    "#     sim = similarity(t1, t2)\n",
    "#     count = 0\n",
    "#     if sim > 0:\n",
    "#         print(t1.id, t2.id, sim)\n",
    "\n",
    "# sets, similarities = similarity_sets(tweetset, k=10, hash_functions=hash_functions,\n",
    "#                                      row_count=2, similarity_cutoff=0)\n",
    "# print(max(tuple(map(len, sets))))\n",
    "\n",
    "# some experimentation\n",
    "try:\n",
    "    df = pd.read_csv('q2_experimentation.csv', index_col=0)\n",
    "except:\n",
    "    hash_functions = [hash_function(i) for i in range(20)] # 50 hashing functions\n",
    "    df = pd.DataFrame(columns=['k','row_count','cutoff','groups'])\n",
    "    for k in range(2, 11):\n",
    "        print('k={}'.format(k))\n",
    "        k*= 3\n",
    "        for row_count in range(1, 5):\n",
    "            print('\\trow_count={}'.format(row_count))\n",
    "            prev_calc = None\n",
    "            for similarity_cutoff in range(10):\n",
    "                similarity_cutoff/=10\n",
    "                sets, prev_calc = similarity_sets(tweetset, k=k, hash_functions=hash_functions,\n",
    "                                             row_count=row_count, similarity_cutoff=similarity_cutoff,\n",
    "                                             precalc_similarities=prev_calc)\n",
    "                df = df.append({'k':float(k),\n",
    "                                'row_count':float(row_count),\n",
    "                                'cutoff':similarity_cutoff,\n",
    "                                'groups':sets\n",
    "                               }, ignore_index=True)\n",
    "    df.to_csv('q2_experimentation.csv')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below, we can see all arguments where some items were matched as similar, but not all.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>row_count</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>groups</th>\n",
       "      <th>group_size</th>\n",
       "      <th>group_sim_count</th>\n",
       "      <th>max_group_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        k  row_count  cutoff  \\\n",
       "0     6.0        1.0     0.0   \n",
       "10    6.0        2.0     0.0   \n",
       "20    6.0        3.0     0.0   \n",
       "40    9.0        1.0     0.0   \n",
       "50    9.0        2.0     0.0   \n",
       "60    9.0        3.0     0.0   \n",
       "80   12.0        1.0     0.0   \n",
       "90   12.0        2.0     0.0   \n",
       "100  12.0        3.0     0.0   \n",
       "120  15.0        1.0     0.0   \n",
       "130  15.0        2.0     0.0   \n",
       "140  15.0        3.0     0.0   \n",
       "160  18.0        1.0     0.0   \n",
       "170  18.0        2.0     0.0   \n",
       "180  18.0        3.0     0.0   \n",
       "200  21.0        1.0     0.0   \n",
       "210  21.0        2.0     0.0   \n",
       "220  21.0        3.0     0.0   \n",
       "240  24.0        1.0     0.0   \n",
       "250  24.0        2.0     0.0   \n",
       "260  24.0        3.0     0.0   \n",
       "280  27.0        1.0     0.0   \n",
       "290  27.0        2.0     0.0   \n",
       "300  27.0        3.0     0.0   \n",
       "320  30.0        1.0     0.0   \n",
       "330  30.0        2.0     0.0   \n",
       "340  30.0        3.0     0.0   \n",
       "\n",
       "                                                groups  \\\n",
       "0    [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "10   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "20   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "40   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "50   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "60   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "80   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "90   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "100  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "120  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "130  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "140  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "160  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "170  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "180  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "200  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "210  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "220  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "240  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "250  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "260  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "280  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "290  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "300  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "320  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "330  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "340  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "\n",
       "                                            group_size  group_sim_count  \\\n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "10   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                9   \n",
       "20   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                9   \n",
       "40   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                9   \n",
       "50   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "60   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "80   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "90   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                7   \n",
       "100  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                7   \n",
       "120  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               10   \n",
       "130  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "140  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "160  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                9   \n",
       "170  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "180  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "200  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "210  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "220  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "240  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "250  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "260  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                7   \n",
       "280  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "290  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "300  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                7   \n",
       "320  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "330  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               10   \n",
       "340  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               11   \n",
       "\n",
       "     max_group_size  \n",
       "0                 5  \n",
       "10                3  \n",
       "20                3  \n",
       "40                4  \n",
       "50                3  \n",
       "60                3  \n",
       "80                3  \n",
       "90                3  \n",
       "100               3  \n",
       "120               3  \n",
       "130               3  \n",
       "140               3  \n",
       "160               3  \n",
       "170               3  \n",
       "180               3  \n",
       "200               3  \n",
       "210               3  \n",
       "220               3  \n",
       "240               3  \n",
       "250               3  \n",
       "260               3  \n",
       "280               4  \n",
       "290               3  \n",
       "300               3  \n",
       "320              17  \n",
       "330               6  \n",
       "340               3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfb = pd.read_csv('q2_experimentation.csv', index_col=0)\n",
    "dfb['groups'] = list(map(eval, dfb['groups'].values))\n",
    "dfb['group_size'] = list(map(lambda x:list(map(len, x)), dfb['groups']))\n",
    "dfb['group_sim_count'] = list(map(lambda x:len([i for i in x if i>1]), dfb['group_size'].values))\n",
    "dfb['max_group_size'] = list(map(lambda x:max(map(len, x)), dfb['groups'].values))\n",
    "dfb = dfb[dfb['max_group_size'] < max(dfb['max_group_size'])]\n",
    "print('below, we can see all arguments where some items were matched as similar, but not all.')\n",
    "similars = dfb[dfb['group_sim_count'] > 0]\n",
    "similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "k: 6.0\n",
      "row count: 1.0\n",
      "group similarity count: 12\n",
      "max group size: 5\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Teaching kids to be triple threat https://t.co/PspNVzKiZJ\n",
      "Obama meets with Asian leaders about North Korea nuke threat --&gt; https://t.co/8ksgGEeEpH\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @FamousWomen: Love is always a demonstration - not just a set of words or a feeling.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Planned weekend trackwork, #AirportLine trains start &amp; end at Central due to City Circle trackwork https://t.co/L5H3pIJnAh\n",
      "Planned weekend trackwork, #WesternLine trains start &amp; end at Central due to City Circle trackwork https://t.co/kwMSLrcPzb\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @GMEAgency: Get the latest #VideoMarketing news-----&gt; https://t.co/IZofzmIBI5\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @danielsahyounie: Can't believe I'm going to be a father soon feeling blessed.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "@danielsahyounie April fools\n",
      "@danielsahyounie happy April fools ya dickhead\n",
      "\n",
      "5 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Tha5SOSFamily: Robert #5SOSFam #BestFanArmy #iHeartAwards\n",
      "RT @Tha5SOSFamily: Clifford #5SOSFam #BestFanArmy #iHeartAwards\n",
      "RT @Tha5SOSFamily: They'll definitely take our lead over night if we keep this up c'mon we can do SO much better.\n",
      "\n",
      "#iHeartAwards #BestFanArâ¦\n",
      "RT @Tha5SOSFamily: Calum #5SOSFam #BestFanArmy #iHeartAwards\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Dubagee: FBI Unlocks San Bernardino Shooters Phone... #breakingnews #funny #SNL https://t.co/JOzNrC6wmH via @YouTube\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Short prices Randwick favourite in doubt https://t.co/5DWR4xH1NB\n",
      "Short priced Randwick favourite in doubt https://t.co/xU8FmemVjZ\n",
      "Short priced Randwick favourite in doubt https://t.co/CBhie9dgTV\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "I posted a new photo to Facebook https://t.co/kYusCqvXD2\n",
      "I posted a new photo to Facebook https://t.co/H1oOGhc9xt\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @KylieJenner: https://t.co/3zCrEwpPlQ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @HITS1031: Support the AACA Clothing KickstarterÂ Campaign https://t.co/lBlJSXFNp0 https://t.co/sE2oas0pZJ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k: 6.0\n",
      "row count: 2.0\n",
      "group similarity count: 9\n",
      "max group size: 3\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @FamousWomen: Love is always a demonstration - not just a set of words or a feeling.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Planned weekend trackwork, #AirportLine trains start &amp; end at Central due to City Circle trackwork https://t.co/L5H3pIJnAh\n",
      "Planned weekend trackwork, #WesternLine trains start &amp; end at Central due to City Circle trackwork https://t.co/kwMSLrcPzb\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @GMEAgency: Get the latest #VideoMarketing news-----&gt; https://t.co/IZofzmIBI5\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @danielsahyounie: Can't believe I'm going to be a father soon feeling blessed.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Tha5SOSFamily: Clifford #5SOSFam #BestFanArmy #iHeartAwards\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Dubagee: FBI Unlocks San Bernardino Shooters Phone... #breakingnews #funny #SNL https://t.co/JOzNrC6wmH via @YouTube\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @KylieJenner: https://t.co/3zCrEwpPlQ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @HITS1031: Support the AACA Clothing KickstarterÂ Campaign https://t.co/lBlJSXFNp0 https://t.co/sE2oas0pZJ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Short priced Randwick favourite in doubt https://t.co/xU8FmemVjZ\n",
      "Short priced Randwick favourite in doubt https://t.co/CBhie9dgTV\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k: 6.0\n",
      "row count: 3.0\n",
      "group similarity count: 9\n",
      "max group size: 3\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @FamousWomen: Love is always a demonstration - not just a set of words or a feeling.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Planned weekend trackwork, #AirportLine trains start &amp; end at Central due to City Circle trackwork https://t.co/L5H3pIJnAh\n",
      "Planned weekend trackwork, #WesternLine trains start &amp; end at Central due to City Circle trackwork https://t.co/kwMSLrcPzb\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @GMEAgency: Get the latest #VideoMarketing news-----&gt; https://t.co/IZofzmIBI5\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @danielsahyounie: Can't believe I'm going to be a father soon feeling blessed.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Tha5SOSFamily: Clifford #5SOSFam #BestFanArmy #iHeartAwards\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Dubagee: FBI Unlocks San Bernardino Shooters Phone... #breakingnews #funny #SNL https://t.co/JOzNrC6wmH via @YouTube\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @KylieJenner: https://t.co/3zCrEwpPlQ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @HITS1031: Support the AACA Clothing KickstarterÂ Campaign https://t.co/lBlJSXFNp0 https://t.co/sE2oas0pZJ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Short priced Randwick favourite in doubt https://t.co/xU8FmemVjZ\n",
      "Short priced Randwick favourite in doubt https://t.co/CBhie9dgTV\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k: 9.0\n",
      "row count: 1.0\n",
      "group similarity count: 9\n",
      "max group size: 4\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @FamousWomen: Love is always a demonstration - not just a set of words or a feeling.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Planned weekend trackwork, #AirportLine trains start &amp; end at Central due to City Circle trackwork https://t.co/L5H3pIJnAh\n",
      "Planned weekend trackwork, #WesternLine trains start &amp; end at Central due to City Circle trackwork https://t.co/kwMSLrcPzb\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @GMEAgency: Get the latest #VideoMarketing news-----&gt; https://t.co/IZofzmIBI5\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @danielsahyounie: Can't believe I'm going to be a father soon feeling blessed.\n",
      "\n",
      "4 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Tha5SOSFamily: Robert #5SOSFam #BestFanArmy #iHeartAwards\n",
      "RT @Tha5SOSFamily: Clifford #5SOSFam #BestFanArmy #iHeartAwards\n",
      "RT @Tha5SOSFamily: Calum #5SOSFam #BestFanArmy #iHeartAwards\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Dubagee: FBI Unlocks San Bernardino Shooters Phone... #breakingnews #funny #SNL https://t.co/JOzNrC6wmH via @YouTube\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @HITS1031: Support the AACA Clothing KickstarterÂ Campaign https://t.co/lBlJSXFNp0 https://t.co/sE2oas0pZJ\n",
      "RT @WiLD983: Support the AACA Clothing KickstarterÂ Campaign https://t.co/7SvjutcWhm https://t.co/pNPHKIxphs\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @KylieJenner: https://t.co/3zCrEwpPlQ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Short priced Randwick favourite in doubt https://t.co/xU8FmemVjZ\n",
      "Short priced Randwick favourite in doubt https://t.co/CBhie9dgTV\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k: 9.0\n",
      "row count: 2.0\n",
      "group similarity count: 8\n",
      "max group size: 3\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @FamousWomen: Love is always a demonstration - not just a set of words or a feeling.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Planned weekend trackwork, #AirportLine trains start &amp; end at Central due to City Circle trackwork https://t.co/L5H3pIJnAh\n",
      "Planned weekend trackwork, #WesternLine trains start &amp; end at Central due to City Circle trackwork https://t.co/kwMSLrcPzb\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @GMEAgency: Get the latest #VideoMarketing news-----&gt; https://t.co/IZofzmIBI5\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @danielsahyounie: Can't believe I'm going to be a father soon feeling blessed.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Tha5SOSFamily: Clifford #5SOSFam #BestFanArmy #iHeartAwards\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Dubagee: FBI Unlocks San Bernardino Shooters Phone... #breakingnews #funny #SNL https://t.co/JOzNrC6wmH via @YouTube\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @HITS1031: Support the AACA Clothing KickstarterÂ Campaign https://t.co/lBlJSXFNp0 https://t.co/sE2oas0pZJ\n",
      "RT @WiLD983: Support the AACA Clothing KickstarterÂ Campaign https://t.co/7SvjutcWhm https://t.co/pNPHKIxphs\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @KylieJenner: https://t.co/3zCrEwpPlQ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(similars.values):\n",
    "    print('\\n\\n\\n')\n",
    "    print('k: {}\\nrow count: {}\\ngroup similarity count: {}\\nmax group size: {}\\n'\n",
    "          .format(*row[:2], *row[-2:]))\n",
    "    for s in row[3]:\n",
    "        if len(s) > 1:\n",
    "            print('{} similar tweets (if less are printed they were exact duplicates of another tweet)'.format(len(s)))\n",
    "            tweets = set()\n",
    "            for tweetid in s:\n",
    "                tweets.add(tweetset[tweetid].body)\n",
    "            for t in tweets:\n",
    "                print(t)\n",
    "            print()\n",
    "    if i>3: # dont print them all.\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise Exception # dont run this it will take ~5 minutes\n",
    "tweetset = {t['actor']['id']:Tweet(t['body'], t['actor']['id']) for _, t in zip(range(50000), stream_tweets())}\n",
    "k = 6\n",
    "row_count = 3\n",
    "sets, prevcalc = similarity_sets(tweetset, k=k, hash_functions=hash_functions, row_count=row_count, similarity_cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Just posted a photo https://t.co/LCJ2dntIfM\n",
      "Just posted a photo https://t.co/YPDEfyYNuo\n",
      "\n",
      "12 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @weeklystandard: A @greenpeaceusa activist thanked @HillaryClinton, then things went sour. https://t.co/5UNjxpks4d #imsosick  https://t.â¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Nero: DEATH THREAT  https://t.co/afoR7txmAS\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @FamousWomen: Love is always a demonstration - not just a set of words or a feeling.\n",
      "\n",
      "8 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "I just checked in at Western Union with #mPLUSPlaces Download today!  https://t.co/BljCYBnGFQ\n",
      "I just checked in at Western Union with #mPLUSPlaces Download today!  https://t.co/UGOwIGLf5p\n",
      "I just checked in at Western Union with #mPLUSPlaces Download today!  https://t.co/5pPirgCNqs\n",
      "I just checked in at Western Union with #mPLUSPlaces Download today!  https://t.co/fNVDNH4Ouj\n",
      "I just checked in at Western Union with #mPLUSPlaces Download today!  https://t.co/8PHXWEKwRY\n",
      "I just checked in at Western Union with #mPLUSPlaces Download today!  https://t.co/bZweU0p0Zb\n",
      "I just checked in at Western Union with #mPLUSPlaces Download today!  https://t.co/uZuDaFZJxh\n",
      "I just checked in at Western Union with #mPLUSPlaces Download today!  https://t.co/b5WXlKj7uc\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "The Union That Just Endorsed Trump is Taking Serious Liberal Fire for Their Surprise Announcement https://t.co/iQ9uhiILU5\n",
      "RT @INJO: The Union That Just Endorsed Trump is Taking Serious Liberal Fire for Their Surprise Announcement https://t.co/dZ9gwGTiPo\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @GMEAgency: Get the latest #VideoMarketing news-----&gt; https://t.co/IZofzmIBI5\n",
      "\n",
      "7 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @bamajr: Think you have to have #WordPress #Multisite? Read \"Donât Use WordPress MultiSite\" by @Ipstenu first! https://t.co/lN52kXuQVQ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @danielsahyounie: Can't believe I'm going to be a father soon feeling blessed.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ChelseaFC: #TBT: Jimmy Floyd Hasselbaink completed a memorable hat-trick with this strike against Spurs back in 2002... https://t.co/1oâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @loudobbsnews: NATO moves to confront Russian threat â @realDonaldTrump doctrine already at work? Gen. Jack Keane joins #LouDobbsTonightâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @LaurenJauregui: And 100 MILLION views on our video..unreallllllâ¤ï¸\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Dubagee: FBI Unlocks San Bernardino Shooters Phone... #breakingnews #funny #SNL https://t.co/JOzNrC6wmH via @YouTube\n",
      "\n",
      "4 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "I liked a @YouTube video from @whiteboy7thst https://t.co/kh6pvxK2Hv Black Market #BLACKOUT (Black Ops 3 Supply Drop Protest)\n",
      "I liked a @YouTube video from @whiteboy7thst https://t.co/8yJyQ1TAaD Black Market #BLACKOUT (Black Ops 3 Supply Drop Protest)\n",
      "I liked a @YouTube video from @whiteboy7thst https://t.co/s3cmfpGEEx Black Market #BLACKOUT (Black Ops 3 Supply Drop Protest)\n",
      "I liked a @YouTube video from @whiteboy7thst https://t.co/KBKFLRAq0o Black Market #BLACKOUT (Black Ops 3 Supply Drop Protest)\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Editorial: The Danger of a Runaway Antarctica: Despite environmental progress, the threat of rising seas must ... https://t.co/aCCFlkfRu7\n",
      "Editorial: The Danger of a Runaway Antarctica: Despite environmental progress, the threat of rising seas must ... https://t.co/XW55Sl7s8A\n",
      "Editorial: The Danger of a Runaway Antarctica: Despite environmental progress, the threat of rising sea... https://t.co/WG4Cubrjdf #world\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "How many followers do you get weekly? 3 awesome new followers for me! Grow with https://t.co/bPec38WEQ4\n",
      "How many followers do you get weekly? 7 awesome new followers for me! Grow with https://t.co/Sa3QixjNVf\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Tim_Beshara: Main thing I am hearing from non-aligned constituents is \"why is Malcolm Turnbull trying to lose the election?\"\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @AustralianOpen: BREAKING: Timber surface to debut at #AusOpen 2017!\n",
      "https://t.co/xFFBSRrexL\n",
      "\n",
      "6 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @weatherchannel: Cameras captured video of a #lightning strike Wednesday afternoon at @OaklawnRacing in Hot Springs, Arkansas. #ARwx\n",
      "httâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "5 5SOS FAM DAY\n",
      "#iHeartAwards #BestFanArmy #5SOSFam\n",
      "104 #iHeartAwards #BestFanArmy #5SOSFam\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "I posted a new photo to Facebook https://t.co/yHozwEv9AH\n",
      "I posted a new photo to Facebook https://t.co/kYusCqvXD2\n",
      "I posted a new photo to Facebook https://t.co/H1oOGhc9xt\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @TasmaniaPolice: Police are today announcing the use of sniffer pigs as part of our drug detection capability.\n",
      "With pigs commonly... httâ¦\n",
      "\n",
      "4 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @GMEAgency: Boogiie Byrd \"Real Life Shyt\" https://t.co/sXl8t7vziz via @YouTube\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @HITS1031: Support the AACA Clothing KickstarterÂ Campaign https://t.co/lBlJSXFNp0 https://t.co/sE2oas0pZJ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Tha5SOSFamily: Clifford #5SOSFam #BestFanArmy #iHeartAwards\n",
      "RT @Tha5SOSFamily: Calum #5SOSFam #BestFanArmy #iHeartAwards\n",
      "\n",
      "8 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @BernieSanders: \"I survived. I became stronger. I have a voice.\" - Andrea Zekis, Transgender Activist #TransDayofVisibility\n",
      "https://t.coâ¦\n",
      "\n",
      "4 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @jccaylen: tomorrow I'm traveling from one place i've never been before to another . dreams are real. ð  australia I'm comingð\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "-- - Beautiful pictures of Uche Jombo, Omoni Oboli, Chioma Akpotha and Ufuoma for wives of strike https://t.co/kW8PIyZMcf + +++\n",
      "ml///// Beautiful pictures of Uche Jombo, Omoni Oboli, Chioma Akpotha and Ufuoma for wives of strike https://t.co/82aoG5fngQ ///\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @AshGhebranious: So Dutton turns up at a conference on helping refugees and suggests we create a system to send them back to country ofâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @JHRtweets: See where the $$$ is going on the Doncaster Mile: https://t.co/oOENdGGD9e\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Short priced Randwick favourite in doubt https://t.co/9UfuIy3IG8\n",
      "Short priced Randwick favourite in doubt https://t.co/1MTTlYVpKM\n",
      "Short priced Randwick favourite in doubt https://t.co/CBhie9dgTV\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @smilleesims: Then, he slid his hand into the leg of my shorts, pulled my thongs to the side and started rubbing on my clit ððð Strike 1\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @RepublicanSwine: Republican Blockade Collapsing As 2 More GOP Senators To Meet Obama SCOTUS Nominee via @politicususa https://t.co/K9YUâ¦\n",
      "RT @1snafu2: Republican Blockade Collapsing As 2 More GOP Senators To Meet Obama SCOTUS Nominee via @politicususa https://t.co/XujVoJ39sX\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @JHRtweets: Injury scare for Country Câship favourite: https://t.co/HkttEM3M62\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @OutFrontCNN: Subtitles detail moment Hillary Clinton loses her cool speaking w/ activist. https://t.co/9VDcfciJLf https://t.co/hNHaiIyQâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Dory: cute april fools day prank: transfer $1,000,000 into my bank account\n",
      "RT @FreddyAmazin: cute april fools day prank: transfer $1,000,000 into my bank account\n",
      "\n",
      "26 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Clinton to climate activist: 'I'm so sick of the Sanders campaign lying about me':  https://t.co/2106TuWWb0\n",
      "Clinton to climate activist: 'I'm so sick of the Sanders campaign lying about me' - CNN https://t.co/Y9kwUk0F05\n",
      "CNN: Hillary Clinton to a climate activist: \"I'm so sick of the Sanders campaign lying about me\" â¦ https://t.co/I0qJdLL5O8\n",
      "Clinton to climate activist: 'I'm so sick of the Sanders campaign lying about me':  https://t.co/9K3HeOj7CL\n",
      "#jhonaiker Clinton to climate activist: 'I'm so sick of the Sanders campaign lying about me':  https://t.co/nlJXDc1cbH #jhonaiker\n",
      "RT @CNNPolitics: Hillary Clinton to a climate activist: \"I'm so sick of the Sanders campaign lying about me\" https://t.co/dIAJSVjE5K https:â¦\n",
      "RT @CNN: Hillary Clinton to a climate activist: \"I'm so sick of the Sanders campaign lying about me\" https://t.co/gazSK8deKk https://t.co/tâ¦\n",
      "#news #world Clinton to climate activist: 'I'm so sick of the Sanders campaign lying about me':  https://t.co/TDbI5eDSCi #recent\n",
      "RT @joefrancis: Clinton snaps at Greenpeace activist: 'I am so sick of the Sanders campaign lying about me' https://t.co/LhEzzQrB9p #news\n",
      "Clinton snaps at Greenpeace activist: 'I am so sick of the Sanders campaign lying about me': The activist pres... https://t.co/sowi7uFEKC\n",
      "#news #world Clinton to climate activist: 'I'm so sick of the Sanders campaign lying about me':  https://t.co/eGYERKfOnq #recent\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Daphne_Lamb: When one of my editor's notes on my manuscript is \"You're evil. I love it.\" I know I'm doing something right. #amwriting\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @TheMurdochTimes: So NewsCorp's @farrm51 has a story on how NewsCorp's Andrew Bolt is still linked to unsolved leak of Top Secret docs hâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Malcolm Turnbull accused of 'doing a runner' over proposal to stop funding public schools https://t.co/sLP8kFpcjn via @smh \"Good on him\".\n",
      "RT @ThumpersAunt: Malcolm Turnbull accused of 'doing a runner' over proposal to stop funding public schools https://t.co/7Mo6BzEL3c via @smh\n",
      "\n",
      "8 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Hm\n",
      "WATCH: Clinton goes off on Greenpeace activist: âI am so sickâ of you bringing up my fossil fuel money https://t.co/zY1hz2fDEd via @Salon\n",
      "Clinton goes off on Greenpeace activist: âI am so sickâ of you bringing up my fossil fuel money https://t.co/nVbh24Py5A via @Salon  @CNN\n",
      "WATCH: Clinton goes off on Greenpeace activist: âI am so sickâ of you bringing up my fossil fuel... https://t.co/OAtkmTHdg3\n",
      "WATCH: Clinton goes off on Greenpeace activist: âI am so sickâ of you bringing up my fossil fuel money https://t.co/cRkr2wJ77k via @Salon\n",
      "RT @SalonSustain: WATCH: Clinton goes off on Greenpeace activist: âI am so sickâ of you bringing up my fossil fuel money https://t.co/P1Bryâ¦\n",
      "#HillaryClinton goes off on Greenpeace activist: âI am so sickâ of you bringing up my fossil fuel money https://t.co/imkmU7ImeL via @Salon\n",
      "RT @Salon: WATCH: Clinton goes off on Greenpeace activist: âI am so sickâ of you bringing up my fossil fuel money https://t.co/VVkMfrBpTZ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @venusboy1977: Maybe @TurnbullMalcolm's 'Thelma&amp;Louise' thing was a clue @tonyowright? He does seem 2b driving @LiberalAus over an #Auspâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "I liked a @YouTube video https://t.co/92kjwZbZlS CSGO - SILVER FIGHT! (Counter Strike: Funny Moments!)\n",
      "I liked a @YouTube video https://t.co/LcFf7MBDjp CSGO - SILVER FIGHT! (Counter Strike: Funny Moments!)\n",
      "I liked a @YouTube video https://t.co/E3fUFfMcAq CSGO - SILVER FIGHT! (Counter Strike: Funny Moments!)\n",
      "\n",
      "8 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "DraftKings and FanDuel strike a deal with NCAA to suspend all college contests https://t.co/oR7hpru9QD\n",
      "DraftKings and FanDuel strike a deal with NCAA to suspend all college contests https://t.co/B0WVcLWKrj\n",
      "DraftKings and FanDuel strike a deal with NCAA to suspend all college contests https://t.co/fAZyb49ugp\n",
      "#Tech: DraftKings and FanDuel strike a deal with NCAA to suspend all college contests https://t.co/v7yjWuDsma\n",
      "#analytics #website DraftKings and FanDuel strike a deal with NCAA to suspend all college contests https://t.co/qpsIOpZCLb #clickcounter\n",
      "DraftKings and FanDuel strike a deal with NCAA to suspend all college contests https://t.co/a92cs1CLb8 #ZippedNews https://t.co/wo198UUwUJ\n",
      "#Tech Update: DraftKings and FanDuel strike a deal with NCAA to suspend all college contests https://t.co/sUXO1bpTsp\n",
      "@TechCrunch Startups | DraftKings and FanDuel strike a deal with NCAA to suspend all college contests https://t.co/2IQhE3u5Rm\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Ashton5SOS: I'm sorry we didn't stay and take photos tonight outside the studio :( we love you\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Quartermain10: So @AFL boss Gill McLachlan wants to relocate a team to New Zealand in the future. \n",
      "That's fine... as long as Tasmania gâ¦\n",
      "So @AFL boss Gill McLachlan wants to relocate a team to New Zealand in the future. \n",
      "That's fine... as long as Tasmania gets one first.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @foxnation: Video: @HillaryClinton Loses Her Cool with Greenpeace Activist: https://t.co/2dyNEivsCc\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @halsey: I'm taking over @mtv snapchat right nowwwwww ð»ð± username: mtv\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Clinton snaps at Greenpeace activist: 'I am so sick of the Sanders campaign lying about me': The activi... https://t.co/9qzWbXfPWJ (Wapo)\n",
      "Clinton snaps at Greenpeace activist: âI am so sick of the Sanders campaign lying about meâ https://t.co/hRS0iyZ7LA\n",
      "Clinton snaps at Greenpeace activist: âI am so sick of the Sanders campaign lying about meâ:    NEW YORK -- A ... https://t.co/hAevEdg1hU\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @BillMoyersHQ: $ in politics is corrupting, but the role that the media industry plays in DC poses a comparable threat to democracy httpâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "#Hit30 Samantha Jade                                          \n",
      "\"Always\"\n",
      "#Hit30 Samantha Jade                                                 \n",
      "\"Always\"\n",
      "#Hit30 Samantha Jade                                           \n",
      "\"Always\"\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @irin: Toby Harmon, full time grassroots antiabortion activist in OK, wouldn't rule out the death penalty for women  https://t.co/oeZvATâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Clinton Tells Greenpeace Activist She's âSick of the Sanders Campaign Lying About Meâ - https://t.co/3yTv2zaaSl\n",
      "#Hillary Clinton Tells Greenpeace Activist She's âSick of the Sanders Campaign Lying About Meâ #jobs #jobsearc... https://t.co/6R6g1KF6QA\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @linessue: Maybe PM Turnbull's state tax plan is an April fool's joke and will disappear by noon? #noidea #aprilfoolsday2016 #auspol\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Hillary Clinton Loses Her Temper With Greenpeace Activist... https://t.co/zG4201RzD8\n",
      "RT @crooksandliars: Hillary Clinton Loses Her Temper With Greenpeace Activist https://t.co/dGSx6xXX2h\n",
      "\n",
      "8 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ggreenwald: Liberals cheering attack on Greenpeace activist for crime of asking about fossil fuel donors #UniteBlue  https://t.co/n3MCVâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Bristow pilots protest, Caverton workers threaten strike https://t.co/FbW01xvq76 #Nigeria #News\n",
      "Bristow pilots protest, Caverton workers threaten strike https://t.co/ysAXkIhDBr\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @smh: .@Sydney_Uni will cut 100 degrees by 2020 and focus on research https://t.co/djwq43kxF5 | @ErykBagshaw\n",
      ".@Sydney_Uni will cut 100 degrees by 2020 and focus on research https://t.co/djwq43kxF5 | @ErykBagshaw\n",
      "\n",
      "5 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "7 people followed me and 10 people unfollowed me // automatically checked by https://t.co/6b8OWMdt9h\n",
      "2 people followed me // automatically checked by https://t.co/IbrQre6ROg\n",
      "2 people followed me and 4 people unfollowed me // automatically checked by https://t.co/GZOEjRCyZS\n",
      "13 people followed me and 5 people unfollowed me // automatically checked by https://t.co/uGcPvzy5vH\n",
      "10 people followed me and 3 people unfollowed me // automatically checked by https://t.co/XriyIjfqPv\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Caradelevingne: I am focusing on filming and trying to learn how to not pick apart my every flaw. I am really good at that\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @KianLawley: I can't believe I'm going to Australia tmrw ð³ I wanna meet as many of u as I can while I'm there ð¨ðð¦ðº\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ACNC_gov_au: LATEST NEWS: Launch of the US Foundation Funding in Australia Report. https://t.co/fmYtVbE2w5 @PhilanthropyAus @KSeibertAuâ¦\n",
      "\n",
      "6 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @RaverVibe: STRIKE IT UP https://t.co/ulf0IUTWPX\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @VinceRugari: not sure where this six weeks stuff has come from re: Robbie Kruse but my info is that he's OK, just he won't play this weâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @TonyHWindsor: Turnbull walks backwards on Gonski consensus for needs based funding to recreate divisive model of the 1960s ...you are bâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @StopNuclearWar: The Greenpeace activist was right. Hillary has taken $160,000 from people working for fossil fuel interests. https://t.â¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @danisnotonfire: 'baa baa black sheep have you any wool?' 'yes sir yes sir three bags full' mate ur talking to a fucking sheep are u onâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @foxandfriends: .@davidwebbshow goes inside an anti-trump protest, and no one seems to know what they are protesting.\n",
      "https://t.co/0qwhyâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @BTS_twt: ì´ëì ìë¯ ì¤í¼ì¬ í¸ìì´ë¤\n",
      "\n",
      "4 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @linnyitssn: So this morning I arrived in Europe and no one is talking about terror threat and everybody is talking about a threat calleâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "My Twitter is worth $1,005.00 today. Find Out Your Vanity Twitter Value Free - Click Here ==&gt; https://t.co/efi4MzsZ3x  #freefollowers\n",
      "My Twitter is worth $1,045.20 today. Find Out Your Vanity Twitter Value Free - Click Here ==&gt; https://t.co/tQUTwcx8kW  #freefollowers\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "USATODAY: Despite a long list of disputes, the U.S. and China strike deals on climate change and nuclear security. https://t.co/Knq8WfyGGE\n",
      "RT @USATODAY: Despite a long list of disputes, the U.S. and China strike deals on climate change and nuclear security. https://t.co/cFm8mZIâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "I liked a @YouTube video https://t.co/7C1OCZdl7O CSGO - SILVER FIGHT! (Counter Strike: Funny Moments!)\n",
      "I liked a @YouTube video https://t.co/ahxgZfRRxm CSGO - SILVER FIGHT! (Counter Strike: Funny Moments!)\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "'Nothing Illegal': Ala. Governor Reacts to Impeachment Threat https://t.co/Jwp7VhnPDZ #sanfrancisco\n",
      "'Nothing Illegal': Ala. Governor Reacts to Impeachment Threat\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @vanbadham: Who pays for our politicians?\n",
      "Official list here: https://t.co/tdmgzUMnHx \n",
      "#auspol\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @thetawlguy: Why write really graphic Escort reviews? She fucked me silly too, but just because I didn't tell the internet doesn't meanâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Nashgrier: If it has to be advertised you probably don't need it\n",
      "\n",
      "6 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Why people overpay at auctions and how to avoid it https://t.co/cdFWtdtrNq\n",
      "Why people overpay at auctions and how to avoid it - https://t.co/aOJ0YjeNDw\n",
      "Why people overpay at auctions and how to avoid it https://t.co/1evTQvLs5v\n",
      "Why people overpay at auctions and how to avoid it - https://t.co/IzL4GLMENk\n",
      "Why people overpay at auctions and how to avoid it - https://t.co/NKgpjZq77H\n",
      "Why people overpay at auctions and how to avoid it - https://t.co/d0jjcMsyeE\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "This week on Wild Melbourne: \n",
      "Ecotourism: https://t.co/IuhrT18BWI\n",
      "Drones: https://t.co/QFlXF76odn\n",
      "Eucalypts: https://t.co/ltryMsy4xE\n",
      "#WildOz\n",
      "RT @WildMelbourne: This week on Wild Melbourne: \n",
      "Ecotourism: https://t.co/IuhrT18BWI\n",
      "Drones: https://t.co/QFlXF76odn\n",
      "Eucalypts: https://t.câ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Perorationer: Bluff called Arthur - Where to now @TurnbullMalcolm ? https://t.co/nPSu2P2PxN\n",
      "\n",
      "4 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @arrenoblair: We're in the Bronx with Rosario Dawson, Harry Belafonte, Spike Lee and Residente. Tune in LIVE:\n",
      " https://t.co/dPywfNEsoj vâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @FOXSportsNews: FUMING: Mark McVeigh tears shreds off our presenter for asking about the fitness of his @sydneyswans brother Jarrad.\n",
      "httâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ConnorFranta: tomorrow im gonna upload a kinda special video and before you ask no its not an april fools joke\n",
      "\n",
      "...or maybe it is?\n",
      "\n",
      "noâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Clinton: 'I'm so sick' of Sanders campaign lying about me | TheHill..Yes.ððºð¸ https://t.co/L5SIkUG2sA\n",
      "RT @hinslgretl: Clinton: 'I'm so sick' of Sanders campaign lying about me | TheHill..Yes.ððºð¸ https://t.co/L5SIkUG2sA\n",
      "\n",
      "57 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "If we are going to rebuild the crumbling middle class, we need to empower workers to exercise their Constitutional right to form a union.\n",
      "RT @SenSanders: If we are going to rebuild the crumbling middle class, we need to empower workers to exercise their Constitutional right toâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @jaketapper: Clinton to climate activist: 'I'm so sick of the Sanders campaign lying about me' - https://t.co/4kGK7SPuhq https://t.co/eqâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Katy Perry, Christina Aguilera sign letter calling for changes to copyright law https://t.co/m1By1KQPQg\n",
      "Katy Perry, Christina Aguilera sign letter calling for changes to copyright law: \n",
      "Hundreds of artists, songwri... https://t.co/DogRUCemjb\n",
      "Katy Perry, Christina Aguilera sign letter calling for changes to copyright law: \n",
      "Hundreds of artists, songwri... https://t.co/jyyGjLpbwf\n",
      "\n",
      "17 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @CNNPolitics: Hillary Clinton to a climate activist: \"I'm so sick of the Sanders campaign lying about me\" https://t.co/dIAJSVjE5K https:â¦\n",
      "RT @CNN: Hillary Clinton to a climate activist: \"I'm so sick of the Sanders campaign lying about me\" https://t.co/gazSK8deKk https://t.co/tâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @lesslinear: We've had a ton of pitches lately on decline of rights in NSW. Here's the most recent â on Baird's anti-protest laws https:â¦\n",
      "\n",
      "11 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/t0uHeeeNWm\n",
      "Clinton: 'Sick of' Sanders camp lies - Hillary Clinton, while being confronted Thursday by a climate activist a... https://t.co/abYwmsyerl\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/tBxT5XsqI0\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/s287CjxZwh\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/xOWNiLNLlu\n",
      "Clinton: 'Sick of' Sanders camp lies - Hillary Clinton, while being confronted Thursday by a climate activist a... https://t.co/X1xk5hdb0P\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/DHPP2RNrvk\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/yuT3TPTTOB\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/GNK29oauU7\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/zehdKsL8sW\n",
      "Clinton: Sick of Sanders camp lies: Hillary Clinton, while being confronted Thursday by a climate activist abo... https://t.co/TqguZXqFvr\n",
      "\n",
      "23 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @BetteMidler: God Bless the State of California and Jerry Brown for being the first state in the union to raise the minimum wage to $15â¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ANI_news: Brussels shows us how real and immediate is the threat to nuclear security from terrorism: PM Modi\n",
      "RT @TimesNow: Brussels shows us how real and immediate is the threat to nuclear security from terrorism: PM Modi #ModiInUS\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @cyclingtips: Just 2 days til one of the best races of the year: the Tour of Flanders! Here's what you should know before watching httpsâ¦\n",
      "Just 2 days til one of the best races of the year: the Tour of Flanders! Here's what you should know before watching https://t.co/HUbbZsMCOo\n",
      "\n",
      "7 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @JustinTrudeau: Canada recognizes nuclear terrorism as a grave threat to international security. Important work with other leaders at #Nâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @SuckMyLEFTJuan: Paul #Keating still has it: âMalcolm #Turnbullâ¦ fundamentally he is a cherry on top of a compost heap.â #auspol https:/â¦\n",
      "RT @BOConnorMP: Paul Keating still has it: âMalcolm Turnbullâ¦ fundamentally he is a cherry on top of a compost heap.â #auspol https://t.co/â¦\n",
      "\n",
      "5 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @weeklystandard: Watch @HillaryClinton explode at a @greenpeaceusa activist https://t.co/7m2LTIeif8 https://t.co/e68sieycDI #ImSoSick\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "April Fools!\n",
      "April Fools!!!\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Rough Justice on target for Hareeba Stakes https://t.co/ShP6xeAx9W\n",
      "Rough Justice on target for Hareeba Stakes https://t.co/HCDLsvupOj\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @BTS_twt: ë ì´ì  ë¹\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Caradelevingne: One more confession...\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @walkleys: Mark your diary: Investigative journalists @SydWritersFest @caromeldrum @suzipeep @quentindempster @pennells - free! https://â¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @AmericanXRoads: This angry response to a @greenpeaceusa activist shows how @BernieSanders is getting to @HillaryClinton. https://t.co/nâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "This site is giving away Free Riot Points #Free #Riot #Points #League of Legends https://t.co/P5RjIZITLB\n",
      "This site is giving away Free Riot Points #Free #Riot #Points #League of Legends https://t.co/K0krKcljkI\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Mine workers at one of Peru's biggest copper deposits plan to go on 48-hour strike starting April 8, union says -... https://t.co/pG3ZTS7jYz\n",
      "#TheNewsClub Mine workers at one of Peru's biggest copper deposits plan to go on 48-hour strike starting April 8, â¦ https://t.co/deMYr3T0va\n",
      "Mine workers at one of Peru's biggest copper deposits plan to go on 48-hour strike starting April 8, union says -â¦ https://t.co/DJwYY9UyTy\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @WiLD983: âDonât Tell Emâ: Jeremih Earns Gold Certification For âLate Nightsâ Album Despite SlowÂ Start https://t.co/PCZWq8JgvA\n",
      "RT @HITS1031: âDonât Tell Emâ: Jeremih Earns Gold Certification For âLate Nightsâ Album Despite SlowÂ Start https://t.co/LsNyDTQDmU\n",
      "RT @EAERADIO: âDonât Tell Emâ: Jeremih Earns Gold Certification For âLate Nightsâ Album Despite SlowÂ Start https://t.co/5nNIDZqclu\n",
      "\n",
      "8 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @mehdifoundation: Whether someone is a fanatic or extremist in #Hinduism, #Christianity, #Judaism or #Islam, we cannot be friends with tâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @AngryVoters: As long as Clinton's under threat of FBI indictment, Sanders is the real front runner \n",
      "#FEELtheBERN #WIprimary #p2\n",
      "https:/â¦\n",
      "RT @AngryVoters: As long as Clinton's under threat of FBI indictment, Sanders is the real front runner \n",
      "#FEELtheBERN #NYprimary #p2\n",
      "https:/â¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @drewdude1229: @10thAmendment @jabney8 They rather have Hillary then Trump. Trump is a threat to there lobby money, Hillary is businessâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Michael5SOS: @5SOS thank u mysterious @5SOS band account @5SOS\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @PhilipStl: BREAKING: Hillary Clinton goes off on Greenpeace activist:  https://t.co/XKkt8fhZrW via @sharethis\n",
      "BREAKING: Hillary Clinton goes off on Greenpeace activist:  https://t.co/XKkt8fhZrW via @sharethis\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @danmericaCNN: Clinton to activist on taking fossil fuel money: \"I'm so sick, I'm so sick of the Sanders campaign lying about me.\" httpsâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @zachhaller: WATCH: Clinton goes off on Greenpeace activist: #ImSoSickâ of you bringing up my fossil fuel money https://t.co/aaD6QGjnUjâ¦\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "A Knightâs Quest Teaser: From creators of Strike Force Heroes and Raze, Sky9 Games is working on new game called Aâ¦ https://t.co/7Tnnk4lSDF\n",
      "A Knightâs Quest Teaser: From creators of Strike Force Heroes and Raze, Sky9 Games is working on new game called Aâ¦ https://t.co/ezkgxrv2un\n",
      "A Knightâs Quest Teaser: From creators of Strike Force Heroes and Raze, Sky9 Games is working on new game called Aâ¦ https://t.co/rQ97U9UcFI\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @AllyBrooke: IN HONOR OF #WORKFROMHOME GOING GOLD, BEING #3 ON ITUNES &amp; 100+ MIL VIEWS...Yolandah and I threw it down...ð\n",
      "https://t.co/wâ¦\n",
      "\n",
      "4 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "So if Daryl dies, will all of you guys actually \"riot\" and stop watching? #TheWalkingDead\n",
      "RT @TheWalkingNews: So if Daryl dies, will all of you guys actually \"riot\" and stop watching? #TheWalkingDead\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Tha5SOSFamily: Relatable \n",
      "#iHeartAwards #BestFanArmy #5SOSFam  https://t.co/sosVvqlS7U\n",
      "\n",
      "6 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @zaynmalik: Just seen Deadpool for the second time , fucking love this shit !! ð\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ChrisCopywriter: ...whole so called 'democratic open capitalist' system is patently abusive @smh Who doesn't understand this doesn't seâ¦\n",
      "...whole so called 'democratic open capitalist' system is patently abusive @smh Who doesn't understand this doesn't see the full picture.\n",
      "\n",
      "7 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @TEDTalks: \"Over and over throughout history, people in power have used fear to silence truth and dissent.\" https://t.co/IMOR1uRII1\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Writeintrump: I'm so Pro-life I won't even say \"Abort!\" when calling off a military strike as President.\n",
      "\n",
      "6 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ryaninnes: If you tell me you're pregnant tomorrow I'm gonna tell you you've been looking a little chubby. #aprilfools\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @tbhyourratchet: Tomorrow is April Fools\n",
      "\n",
      "who needs April Fools when your whole life is a joke.\n",
      "RT @Dory: Tomorrow is April Fools\n",
      "\n",
      "who needs April Fools when your whole life is a joke.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @michellemungall: Better to support #BCNDP bill to ban corporate &amp; union donations. Just take big money out of #bcpoli. https://t.co/2vSâ¦\n",
      "\n",
      "8 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "NEARBY NEWS: FBI Investigating Suspicious Devices, College Shooter Threat, Gostkowski's iPad Recovered and More https://t.co/XmPcT36hGg\n",
      "NEARBY NEWS: FBI Investigating Suspicious Devices, College Shooter Threat, Gostkowski's iPad Recovered and More https://t.co/4QPEoHgTLd\n",
      "NEARBY NEWS: FBI Investigating Suspicious Devices, College Shooter Threat, Gostkowski's iPad Recovered and More https://t.co/5qlFIvjJ3p\n",
      "NEARBY NEWS: FBI Investigating Suspicious Devices, College Shooter Threat, Gostkowski's iPad Recovered and More https://t.co/Pp3FbCFnkY\n",
      "NEARBY NEWS: FBI Investigating Suspicious Devices, College Shooter Threat, Gostkowski's iPad Recovered and More https://t.co/ZoV20RG9Ax\n",
      "NEARBY NEWS: FBI Investigating Suspicious Devices, College Shooter Threat, Gostkowski's iPad Recovered and More https://t.co/uB3cCnTG19\n",
      "NEARBY NEWS: FBI Investigating Suspicious Devices, College Shooter Threat, Gostkowski's iPad Recovered and More https://t.co/qTpbWYLSmn\n",
      "NEARBY NEWS: FBI Investigating Suspicious Devices, College Shooter Threat, Gostkowski's iPad Recovered and More https://t.co/EGRBUZmxmy\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Mike_Beacham: Sharpton Predicts Unrest In The Streets Once Obama Leaves Office \n",
      "https://t.co/kFMAvMKoKo \n",
      "Prosecute-CRIMINAL-RACE-BAITERâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ycfan: My friend just texted me she downloaded t100...\n",
      "\n",
      "I forgot to tell her not to bother ð\n",
      "\n",
      "BURY TROPES NOT US @TheCW\n",
      "My friend just texted me she downloaded t100...\n",
      "\n",
      "I forgot to tell her not to bother ð\n",
      "\n",
      "BURY TROPES NOT US @TheCW\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "What would media have said if @TonyAbbottMHR had proposed taking all funding from pub schools, dbl income tax &amp; kept on Sinodinos ? #auspol\n",
      "RT @evanevanhughes: What would media have said if @TonyAbbottMHR had proposed taking all funding from pub schools, dbl income tax &amp; kept onâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @Kon__K: A 17th woman has just been killed in Australia in 2016\n",
      "\n",
      "That's one woman killed every 5 days\n",
      "\n",
      "That's a national disgrace\n",
      "\n",
      "Men mâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @NahBabyNah: Video: Hillary Clinton Loses It When Confronted By Greenpeace Activist Over Fossil Fuel Donationsâ¦ https://t.co/LGvBgfyB6Râ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @cushbomb: WATCH: Margaret Thatcher's epic clapback on hunger strike-bros.\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @michaelallenmar: Twitter Just Reacted to Hillary Clinton Flipping Out on Climate Activist https://t.co/Oymj7gFfYJ\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @formwa: \" I think arts &amp; creativity are essential to the health of any city,\" @deborahcullinan on @RTRFM for the launch of #PUBLIC2016â¦\n",
      "\" I think arts &amp; creativity are essential to the health of any city,\" @deborahcullinan on @RTRFM for the launch of #PUBLIC2016 today\n",
      "\n",
      "5 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @SpeedyCanaries: If Octavia isn't able to say goodbye to Lincoln I riot. #The100\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @OnThisDateFacts: 1948 â Cold War: Berlin Airlift â Military forces set-up a land blockade of West Berlin\n",
      "1948 â Cold War: Berlin Airlift â Military forces set-up a land blockade of West Berlin\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @rolandsmartin: 4th LINE OF THE NIGHT: \"You are officially the worst!\" Marcus @CorneliusSJr just read Mellie @BellamyYoung the riot act!â¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @jennamclarke: WA to get it's own Clive Palmer at the next state election #wapol  https://t.co/Knjd02zPUU\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Chicago Teachers Strike: CPS teachers, parents prepare for 1-day strike â WLS-TV https://t.co/dTCMGlILYL\n",
      "Chicago Teachers Strike: CPS teachers, parents prepare for 1-day strike - WLS-TV - https://t.co/KEhIe3sMkG\n",
      "Chicago Teachers Strike: CPS teachers, parents prepare for 1-day strike - WLS-TV - https://t.co/Bel1F48c58\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @amperg33: Must read ð¡ð¡ð¡FRAUD: Michelle Fields's Honduran Born Mama Is Pro-Amnesty, Anti-Trump Activist #GrabGate https://t.co/dZuYKhqqLâ¦\n",
      "\n",
      "20 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/ORWuEEIud0\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/c7iSUfWPFH\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/eJmM7jvLUw\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/xC0ZWiK6f4\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/NKRrZbfnm1\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/1a4CpV5eXa\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/0HMrPM8s9k\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/wuJgpGj4ZK\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/i7SZpzmSdp\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/hu2FmTGGEa\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with ... https://t.co/4l0xPvR1vr #UberTalks\n",
      "T-shirt predicts a riot of a time at GOP convention https://t.co/sDo38dKG8c \n",
      "\n",
      "A Cleveland musician is having some fun with this doozy of aâ¦\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/Mg32RoOUUo\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/QGv8zVeq2k\n",
      "T-shirt predicts a riot of a time at GOP convention - A Cleveland musician is having some fun with this doozy o... https://t.co/EW8rZuDWD1\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/YnESgHVVYD\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/K2NyYffNoH\n",
      "#01Molleto T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is ha... https://t.co/3IkvxnkrV8 #HerreraTeamSwagga\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/KfK5EJl4ci\n",
      "T-shirt predicts a riot of a time at GOP convention: \n",
      "A Cleveland musician is having some fun with this doozy ... https://t.co/LWfCaJMtyH\n",
      "\n",
      "13 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "T-shirt predicts a riot of a time at GOP convention https://t.co/sO0ke85IGR\n",
      "#T-shirt predicts a riot of a time at GOP convention https://t.co/huYIqe5RVF\n",
      "T-shirt predicts a riot of a time at GOP convention https://t.co/2eXPQIZa1a\n",
      "âº T-shirt predicts a riot of a time at GOP convention https://t.co/sGjcWZNhjn\n",
      "T-shirt predicts a riot of a time at GOP convention https://t.co/K1xBdFkgon #TechText\n",
      "\"T-shirt predicts a riot of a time at GOP convention\" https://t.co/W3aWGW8LlP\n",
      "T-shirt predicts a riot of a time at GOP convention: https://t.co/6kRX3yen8Z\n",
      "T-shirt predicts a riot of a time at GOP convention https://t.co/ZEd98sOQVf\n",
      "T-shirt predicts a riot of a time at GOP convention https://t.co/KPQau17xbW\n",
      "T-shirt predicts a riot of a time at GOP convention https://t.co/Jwrlo32cBc\n",
      "RT @EmperorDarroux: T-shirt predicts a riot of a time at GOP convention https://t.co/QrU4zzy5CQ\n",
      "T-shirt predicts a riot of a time at GOP convention... https://t.co/eB2pSTMjs7 #news\n",
      "Mashable : T-shirt predicts a riot of a time at GOP convention https://t.co/S0SZTm9tDw\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Clinton Lashes Out at Environmental Activist: A visibly angry Hillary Clinton lashed out a... https://t.co/U2nzWl3y2O (via @EricBarbosa11\n",
      "Clinton Lashes Out at Environmental Activist: A visibly angry Hillary Clinton lashed out at an environmental a... https://t.co/XHYm0qcc8U\n",
      "\n",
      "3 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @AyeshaASiddiqi: bigot: \"I did this bc I'm racist, wanted to do a hate crime\"\n",
      "media: \"hard to say what motivated this incident, reasonsâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "Why lie all the time!! Then make me strike you down..admit you stupid heartless bitch!! You are trying to make $$$$$off me?? Fuck u lyin rat\n",
      "RT @LaurenBloveu: Why lie all the time!! Then make me strike you down..admit you stupid heartless bitch!! You are trying to make $$$$$off mâ¦\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ScottWarner18: The Warriors will win the NBA Finals this year.  Guaranteed.\n",
      "\n",
      "2 similar tweets (if less are printed they were exact duplicates of another tweet)\n",
      "RT @ShawnMendes: I love the gym. Best vibe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sets:\n",
    "    if len(s) > 1:\n",
    "        print('{} similar tweets (if less are printed they were exact duplicates of another tweet)'.format(len(s)))\n",
    "        tweets = set()\n",
    "        for tweetid in s:\n",
    "            tweets.add(tweetset[tweetid].body)\n",
    "        for t in tweets:\n",
    "            print(t)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# answers:\n",
    "1. What value of $k$ did you use to represent the $k$-shingles and why?\n",
    "\n",
    "through experimentation, the best results were seen with smaller numbers of k, but greater then about 5. Greater numbers then 5 are used as hashes would have too many matches and the possible number of sets for a tweet gets reduced, meaning the ordering of the text has much less meaning, and the meaning is more in specifically what letters are contained. (imagine k=1, each tweets value set would just be single characters contained in it)\n",
    "\n",
    "\n",
    "2. Did you hash the $k$-shingles and why?\n",
    "\n",
    "I did hash the k-shingles as it reduced the runtime of the application by making each following hash on the hash less time consuming.\n",
    "\n",
    "\n",
    "3. If you hashed the $k$-shingles, how many buckets did you use and why?\n",
    "\n",
    "I did not limit the standard python hash function with a number of bins as to preserve uniqueness, at no cost.\n",
    "\n",
    "4. How many hashes did you use for minhashing, how many buckets, and why?\n",
    "\n",
    "I used 400 hashes for minhashing, and again i did not limit the number of buckets (all hashes in python are < 2**(chipset size of python install IE 32 or 64))\n",
    "\n",
    "\n",
    "5. How many bands and rows did you use for locality-sensitive hashing and why?\n",
    "\n",
    "I used bands of size \\[1, 3\\], as more just removed individuality between tweets. using 3 seemed to minimize runtime while maximizing similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>row_count</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>groups</th>\n",
       "      <th>group_size</th>\n",
       "      <th>group_sim_count</th>\n",
       "      <th>max_group_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{id:twitter.com:18064228}, {id:twitter.com:18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        k  row_count  cutoff  \\\n",
       "0     6.0        1.0     0.0   \n",
       "10    6.0        2.0     0.0   \n",
       "20    6.0        3.0     0.0   \n",
       "40    9.0        1.0     0.0   \n",
       "50    9.0        2.0     0.0   \n",
       "60    9.0        3.0     0.0   \n",
       "80   12.0        1.0     0.0   \n",
       "90   12.0        2.0     0.0   \n",
       "100  12.0        3.0     0.0   \n",
       "120  15.0        1.0     0.0   \n",
       "130  15.0        2.0     0.0   \n",
       "140  15.0        3.0     0.0   \n",
       "160  18.0        1.0     0.0   \n",
       "170  18.0        2.0     0.0   \n",
       "180  18.0        3.0     0.0   \n",
       "200  21.0        1.0     0.0   \n",
       "210  21.0        2.0     0.0   \n",
       "220  21.0        3.0     0.0   \n",
       "240  24.0        1.0     0.0   \n",
       "250  24.0        2.0     0.0   \n",
       "260  24.0        3.0     0.0   \n",
       "280  27.0        1.0     0.0   \n",
       "290  27.0        2.0     0.0   \n",
       "300  27.0        3.0     0.0   \n",
       "320  30.0        1.0     0.0   \n",
       "330  30.0        2.0     0.0   \n",
       "340  30.0        3.0     0.0   \n",
       "\n",
       "                                                groups  \\\n",
       "0    [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "10   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "20   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "40   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "50   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "60   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "80   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "90   [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "100  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "120  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "130  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "140  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "160  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "170  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "180  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "200  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "210  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "220  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "240  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "250  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "260  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "280  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "290  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "300  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "320  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "330  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "340  [{id:twitter.com:18064228}, {id:twitter.com:18...   \n",
       "\n",
       "                                            group_size  group_sim_count  \\\n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "10   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                9   \n",
       "20   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                9   \n",
       "40   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                9   \n",
       "50   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "60   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "80   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "90   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                7   \n",
       "100  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                7   \n",
       "120  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               10   \n",
       "130  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "140  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "160  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                9   \n",
       "170  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "180  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "200  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "210  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "220  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "240  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "250  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "260  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                7   \n",
       "280  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "290  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                8   \n",
       "300  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                7   \n",
       "320  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               12   \n",
       "330  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               10   \n",
       "340  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               11   \n",
       "\n",
       "     max_group_size  \n",
       "0                 5  \n",
       "10                3  \n",
       "20                3  \n",
       "40                4  \n",
       "50                3  \n",
       "60                3  \n",
       "80                3  \n",
       "90                3  \n",
       "100               3  \n",
       "120               3  \n",
       "130               3  \n",
       "140               3  \n",
       "160               3  \n",
       "170               3  \n",
       "180               3  \n",
       "200               3  \n",
       "210               3  \n",
       "220               3  \n",
       "240               3  \n",
       "250               3  \n",
       "260               3  \n",
       "280               4  \n",
       "290               3  \n",
       "300               3  \n",
       "320              17  \n",
       "330               6  \n",
       "340               3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfb[dfb['max_group_size'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (5 marks)\n",
    "Implement a MapReduce version of PageRank **using combiners** as described in the lectures of week 9. The MapReduce version should incorporate teleporting with $\\beta=0.85$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will use Python's built-in functions `map` and `reduce`. For example, the following code is a Python version that uses MapReduce to compute the sum of squares of the numbers in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "def my_square(x):\n",
    "    return x**2\n",
    "\n",
    "def my_sum(x,y):\n",
    "    return x+y\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "def mapreduce(a_list):\n",
    "    temp = map(my_square, a_list) # Note that map returns an iterator, not a list\n",
    "    return reduce(my_sum, temp)\n",
    "\n",
    "mapreduce(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2**2+3**2+4**2+5**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above Python code is not efficient and it does not take advantage of parallel computing units (feel free to search the Web for parallel versions) but it will serve for this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `map` returns a Python iterator and not a list and there are operations that cannot be performed on it. For example, you cannot select a slice or compute the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'map' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b960b2a81dba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_square\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'map' has no len()"
     ]
    }
   ],
   "source": [
    "temp = map(my_square, my_list)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = map(my_square, my_list)\n",
    "print(temp[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, use an artificially generated network such as the one used in the workshop of week 9. The code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network(n, sparsity):\n",
    "    \"Return a transition matrix with n nodes\"\n",
    "    # Fill the matrix\n",
    "    result = np.zeros((n,n))\n",
    "    for i in range(int(n*n - n*n*sparsity)):\n",
    "        x = np.random.randint(n)\n",
    "        y = np.random.randint(n)\n",
    "        result[x,y] = 1\n",
    "        \n",
    "    # Normalise the results\n",
    "    for c in range(n):\n",
    "        degree = np.sum(result[:, c])\n",
    "        if degree > 0:\n",
    "            result[:, c] /= degree\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_network(5,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In your demonstration, generate a network with 20 nodes and compute the PageRank of each node. \n",
    "* Your solution must include a graph that shows how the PageRank changes at each iteration.\n",
    "* Do not attempt to remove dead ends (to simplify this exercise).\n",
    "* What size of blocks did you use for your solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M = generate_network(20, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code does not use MapReduce (it's based on the lecture notebook). Use it for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epsillon = 0.0001\n",
    "beta = 0.85\n",
    "page_count = 20\n",
    "M = generate_network(page_count, 0.7)\n",
    "PR = np.ones((page_count, 1)) / page_count\n",
    "iterations = 0\n",
    "oldPR = np.zeros((page_count,1))\n",
    "allPR = [PR]\n",
    "while max(np.abs(oldPR-PR)) > epsillon:\n",
    "    oldPR = PR\n",
    "    PR = beta*(np.dot(M, PR)) + (1-beta)/page_count*np.ones((page_count,1))\n",
    "    allPR.append(PR)\n",
    "    iterations += 1\n",
    "print(\"PR after %i iterations:\" % iterations)\n",
    "print(PR)\n",
    "print(sum(PR.T[0]))\n",
    "for p in range(page_count):\n",
    "    data = [onePR[p,0] for onePR in allPR]\n",
    "    plt.plot(data)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"PageRank\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the solution with MapReduce below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Constants = namedtuple('Constants', ['epsillon','beta', 'page_count'])\n",
    "c = Constants(epsillon, beta, len(M))\n",
    "from itertools import chain\n",
    "\n",
    "def tuplify(f):\n",
    "    def r(*x, **xx):\n",
    "        return tuple(f(*x, **xx))\n",
    "    return r\n",
    "\n",
    "# @tuplify\n",
    "def map_pagerank(key_value, constants=c):\n",
    "    key, value = key_value\n",
    "    # input------------------------------------\n",
    "    # key: (page, pagerank)\n",
    "    # value: itterable of outgoing links\n",
    "    \n",
    "    # NOTE TO THE MARKER:\n",
    "    # the time is 11:43 and I have to leave for work in 10 minutes.\n",
    "    # I did not properly read the question so I am going to leave the dead-end\n",
    "    # removal in as I have already written it, and I dont have time to change and test again.\n",
    "    for v in value: \n",
    "        yield v, ((key[1] / len(value)) * (1-constants.beta), ()) # transversal \n",
    "    yield (key[0],\n",
    "    (constants.beta / constants.page_count, value)) # teleportation\n",
    "    # output-----------------------------------\n",
    "    # key: page\n",
    "    # value: (pagerank, outgoing links)\n",
    "    \n",
    "\n",
    "# @tuplify\n",
    "def reduce_pagerank(key_values, constants=c):\n",
    "    key, values = key_values\n",
    "    # input-----------------------------------\n",
    "    # key: page\n",
    "    # values: itterable of (pagerank, outgoing links)s\n",
    "    outlinks = []\n",
    "    pagerank = 0\n",
    "    for pr, ol in values:\n",
    "        outlinks += list(ol)\n",
    "        pagerank += pr\n",
    "    yield (key, pagerank), tuple(outlinks)\n",
    "    # output-----------------------------------\n",
    "    # key: (page, pagerank)\n",
    "    # value: tuple of outgoing links\n",
    "\n",
    "\n",
    "# @tuplify\n",
    "def prepare_reduce(key_value_pairs, constants=c):\n",
    "    # function takes all key value pairs and groups them by key.\n",
    "    # this returns the format:\n",
    "    # key : itterable of values that had that key\n",
    "    rval = {}\n",
    "    for key, value in key_value_pairs:\n",
    "        if key not in rval:\n",
    "            rval[key] = set()\n",
    "        rval[key].add(value)\n",
    "    for key in rval:\n",
    "        yield key, tuple(rval[key])\n",
    "\n",
    "\n",
    "# @tuplify\n",
    "def prepare_map(network_matrix):\n",
    "    for pagenumber, row in enumerate(network_matrix):\n",
    "        yield (pagenumber, 1/len(network_matrix)), tuple(i for i in range(len(network_matrix)) if row[i] != 0)\n",
    "\n",
    "        \n",
    "# @tuplify\n",
    "def mapchain(function, args):\n",
    "    return chain(*map(function, args)) # chains all values returned by function together.\n",
    "\n",
    "\n",
    "@tuplify # left this here to calculate epsillon (otherwise generators will finish\n",
    "# in calculating epsillon, and wont be available to calculate the next itteration of mapreduce)\n",
    "def mapreduce(values, map_function=map_pagerank, reduce_function=reduce_pagerank, constants=c):\n",
    "    d = values\n",
    "    d = mapchain(lambda x:map_pagerank(x, constants=c), d)\n",
    "    d = prepare_reduce(d)\n",
    "    d = mapchain(lambda x:reduce_pagerank(x, constants=c), d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = generate_network(page_count, .7)\n",
    "d = tuple(prepare_map(M))\n",
    "old = np.array(tuple(map(lambda x:x[0][1], sorted(d, key=lambda x:x[0][0]))))\n",
    "maxdiff = 1\n",
    "count = 0\n",
    "all_ranks = [old]\n",
    "c = Constants(.0001, .85, len(M))\n",
    "while maxdiff > c.epsillon:\n",
    "    d = mapreduce(d, )\n",
    "    current = np.array(tuple(map(lambda x:x[0][1], sorted(d, key=lambda x:x[0][0]))))\n",
    "    maxdiff = max(np.abs(current - old))\n",
    "    old = current\n",
    "    all_ranks.append(current)\n",
    "    count += 1\n",
    "all_ranks = np.array(all_ranks)\n",
    "print('PR after {} itterations:'.format(count))\n",
    "print(np.array([current]).T)\n",
    "print(sum(all_ranks[0]))\n",
    "plt.plot(range(len(all_ranks)),all_ranks)\n",
    "plt.show()\n",
    "# epsylon beta page_count M "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
